We create a Hierarchical Transformer for  and an attention-aware inference algorithm for neural abstractive summarization, 

Preparation
-------
 You can find the best checkpoints from https://pan.baidu.com/s/1Jiccf2_f9zJ4CB7e0V2coA code: e3vd
 
 The ranked WikiSum dataset from https://github.com/nlpyang/hiersumm
 
 You should dowload above checkpoints and dataset and put them in your project.
